{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkuRAwJqN7jh",
        "outputId": "f70088c1-75a7-46da-87d6-66a65f2fd743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sliding Window Cross-Validation Results:\n",
            "Mean Accuracy: 0.4829\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "training_data = pd.read_excel('/content/Premier_League_Date_Combined_Modified_2.0 - Training Set.xlsx')\n",
        "\n",
        "# Define the feature columns and target variable\n",
        "features = [\n",
        "    'LSPR',    # Last Season Possession Ratio\n",
        "    'LSGFD',   # Last Season Goals For Difference\n",
        "    'LSGAD',   # Last Season Goals Against Difference\n",
        "    'LSYCD',   # Last Season Yellow Cards Difference\n",
        "    'LSPD',    # Last Season Penalty Difference\n",
        "    'LSSPR',   # Last Season Save Percentage Ratio\n",
        "    'LSCSPR',  # Last Season Clean Sheet Percentage Ratio\n",
        "    'R5PD',    # Recent 5 Games Points Difference\n",
        "    'R5GFD',   # Recent 5 Games Goals For Difference\n",
        "    'R5GAD',   # Recent 5 Games Goals Against Difference\n",
        "    'TSSD',    # This Season Squad Difference\n",
        "    'TSAD',    # This Season Age (Average) Difference\n",
        "    'TSFD',    # This Season Foreigners Difference\n",
        "    'TSTMR',   # This Season Total Market Ratio\n",
        "    'R3VATGD', # Recent 3 Versus Away Team Goals Difference\n",
        "    'R3VATP'   # Recent 3 Vercus Away Team Points\n",
        "]\n",
        "outcome_label = 'Outcome_Label'\n",
        "\n",
        "# Define seasons for sliding window CV\n",
        "seasons = ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022']\n",
        "\n",
        "# Store results for each fold\n",
        "fold_results = []\n",
        "\n",
        "# Sliding window cross-validation\n",
        "for i in range(2, len(seasons) - 1):\n",
        "    # Define training and test seasons\n",
        "    train_seasons = seasons[i - 2:i]\n",
        "    test_season = seasons[i + 1]\n",
        "\n",
        "    # Filter training and testing data\n",
        "    X_train = training_data[training_data['Season'].isin(train_seasons)][features]\n",
        "    y_train = training_data[training_data['Season'].isin(train_seasons)][outcome_label]\n",
        "    X_test = training_data[training_data['Season'] == test_season][features]\n",
        "    y_test = training_data[training_data['Season'] == test_season][outcome_label]\n",
        "\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Convert labels to categorical (one-hot encoding)\n",
        "    num_classes = len(y_train.unique())\n",
        "    y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
        "    y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "    # Build the neural network model\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Input layer\n",
        "        Dropout(0.2),  # Dropout for regularization\n",
        "        Dense(64, activation='relu'),  # Hidden layer\n",
        "        Dropout(0.2),  # Dropout for regularization\n",
        "        Dense(num_classes, activation='softmax')  # Output layer for multi-class classification\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_scaled, y_train_encoded, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_encoded, verbose=0)\n",
        "    fold_results.append(test_accuracy)\n",
        "\n",
        "# Summary of sliding window CV results\n",
        "print(\"\\nSliding Window Cross-Validation Results:\")\n",
        "print(f\"Mean Accuracy: {np.mean(fold_results):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data = pd.read_excel('/content/Premier_League_Date_Combined_Modified_2.0 - Testing Set.xlsx')\n",
        "\n",
        "# Prepare the training data\n",
        "X = training_data[features]\n",
        "y = training_data[outcome_label]\n",
        "X_test = testing_data[features]\n",
        "y_test = testing_data[outcome_label]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled_test = scaler.fit_transform(X_test)\n",
        "\n",
        "# Convert labels to categorical (one-hot encoding)\n",
        "num_classes = len(y.unique())\n",
        "y_encoded = to_categorical(y, num_classes=num_classes)\n",
        "y_encoded_test = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_scaled.shape[1],)),  # Input layer\n",
        "    Dropout(0.2),  # Dropout for regularization\n",
        "    Dense(64, activation='relu'),  # Hidden layer\n",
        "    Dropout(0.2),  # Dropout for regularization\n",
        "    Dense(num_classes, activation='softmax')  # Output layer for multi-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the entire training set\n",
        "history = model.fit(X_scaled, y_encoded, epochs=50, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = model.evaluate(X_scaled, y_encoded, verbose=0)\n",
        "print(f\"\\nTraining Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "test_loss, test_accuracy = model.evaluate(X_scaled_test, y_encoded_test, verbose=0)\n",
        "print(f\"\\nTesting Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Generate predictions and evaluate the confusion matrix\n",
        "y_pred = np.argmax(model.predict(X_scaled), axis=1)\n",
        "y_pred_test = np.argmax(model.predict(X_scaled_test), axis=1)\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nTraining Confusion Matrix:\")\n",
        "print(confusion_matrix(y, y_pred))\n",
        "print(\"\\nTesting Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giKkOncy53aX",
        "outputId": "f05704a6-07a5-4715-fe41-c2ac2ef47b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4982 - loss: 1.0154\n",
            "Epoch 2/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5243 - loss: 0.9873\n",
            "Epoch 3/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5486 - loss: 0.9653\n",
            "Epoch 4/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5289 - loss: 0.9848\n",
            "Epoch 5/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5497 - loss: 0.9684\n",
            "Epoch 6/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5483 - loss: 0.9602\n",
            "Epoch 7/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5502 - loss: 0.9516\n",
            "Epoch 8/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5475 - loss: 0.9495\n",
            "Epoch 9/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5623 - loss: 0.9337\n",
            "Epoch 10/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5606 - loss: 0.9493\n",
            "Epoch 11/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5453 - loss: 0.9581\n",
            "Epoch 12/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5675 - loss: 0.9498\n",
            "Epoch 13/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5551 - loss: 0.9393\n",
            "Epoch 14/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5432 - loss: 0.9482\n",
            "Epoch 15/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5482 - loss: 0.9413\n",
            "Epoch 16/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5725 - loss: 0.9288\n",
            "Epoch 17/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5621 - loss: 0.9393\n",
            "Epoch 18/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5699 - loss: 0.9321\n",
            "Epoch 19/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5791 - loss: 0.9108\n",
            "Epoch 20/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5631 - loss: 0.9151\n",
            "Epoch 21/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5736 - loss: 0.9083\n",
            "Epoch 22/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 0.8852\n",
            "Epoch 23/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5765 - loss: 0.9195\n",
            "Epoch 24/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 0.9046\n",
            "Epoch 25/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5930 - loss: 0.8953\n",
            "Epoch 26/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: 0.8810\n",
            "Epoch 27/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5787 - loss: 0.8995\n",
            "Epoch 28/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6019 - loss: 0.8845\n",
            "Epoch 29/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5948 - loss: 0.8834\n",
            "Epoch 30/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5961 - loss: 0.8763\n",
            "Epoch 31/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6082 - loss: 0.8550\n",
            "Epoch 32/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6121 - loss: 0.8787\n",
            "Epoch 33/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6122 - loss: 0.8524\n",
            "Epoch 34/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6012 - loss: 0.8679\n",
            "Epoch 35/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5970 - loss: 0.8752\n",
            "Epoch 36/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6230 - loss: 0.8506\n",
            "Epoch 37/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6197 - loss: 0.8436\n",
            "Epoch 38/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6339 - loss: 0.8317\n",
            "Epoch 39/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6084 - loss: 0.8511\n",
            "Epoch 40/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6241 - loss: 0.8343\n",
            "Epoch 41/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6246 - loss: 0.8524\n",
            "Epoch 42/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6493 - loss: 0.8083\n",
            "Epoch 43/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6112 - loss: 0.8272\n",
            "Epoch 44/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6326 - loss: 0.8181\n",
            "Epoch 45/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6279 - loss: 0.8431\n",
            "Epoch 46/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6333 - loss: 0.8277\n",
            "Epoch 47/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6238 - loss: 0.8068\n",
            "Epoch 48/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6367 - loss: 0.7909\n",
            "Epoch 49/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6420 - loss: 0.7900\n",
            "Epoch 50/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6381 - loss: 0.8157\n",
            "\n",
            "Training Accuracy: 71.05%\n",
            "\n",
            "Testing Accuracy: 51.05%\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "\n",
            "Training Confusion Matrix:\n",
            "[[655  45 159]\n",
            " [153 246 225]\n",
            " [140  48 989]]\n",
            "\n",
            "Testing Confusion Matrix:\n",
            "[[ 68  12  43]\n",
            " [ 34   7  41]\n",
            " [ 38  18 119]]\n"
          ]
        }
      ]
    }
  ]
}